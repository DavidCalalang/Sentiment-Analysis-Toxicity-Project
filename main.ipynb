{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b560fc6-13e0-4d44-9b99-db93161b4919",
   "metadata": {},
   "source": [
    "# Installing Libraries & Loading .csv Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5276ce-0eab-46b8-bc9c-3fe7c545346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a55d8c-d88f-412b-a6e1-a64c17643990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 11:54:00.857477: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 11:54:00.857593: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 11:54:00.860781: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-06 11:54:01.142661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 11:54:02.772545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb8686b-fc1b-44a6-ac19-64ca97f053cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to work around a \"Error tokenizing error\", specifically modifying parser engine to python\n",
    "data = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv'), engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8da1e61-51de-45df-b923-461c67a0f09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb727d24-17a5-4c7f-8daa-809622745b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d7d8f0b-a07c-4719-a2e0-4fae659e3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this particular dataset, notice that each comment is uniquely identified with the 'id' column, but more importantly, each comment contains labels specifying different types of toxicities that a comment could have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec2830-15be-4f5d-9391-b3894f5ca58d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d329efd-b7f8-45cb-acea-e7af5eadd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing tensorflow's in-built vectorization tool to tokenize our data values.\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd42bb6-fda6-4cbd-b1ed-faf7440c6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting by comments and their corresponding toxicity labels\n",
    "x = data['comment_text']\n",
    "y = data[data.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8435784-0346-44d4-9cb6-1025739f8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher -> possibly more accurate but slower model\n",
    "MAX_WORDS = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53260b6e-2870-4587-acc1-50fac183227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 11:54:22.665684: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Capping model to only take max 1800 tokens per comment\n",
    "vectorizer = TextVectorization(max_tokens=MAX_WORDS,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737c0adf-b345-44c7-a9a6-571814704e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All words/tokens within our comments data is learned by the vectorizer\n",
    "vectorizer.adapt(x.values)\n",
    "\n",
    "# vectorized_text now contains the translated comments to our custom vectorizer (represented as integers)\n",
    "vectorized_text = vectorizer(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65a8754-8422-4116-88f4-e5efa06b4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data pipeline\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f8ae21d-c26c-4305-b9cc-ad39f5041310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating traning, validation and testing dataset splits\n",
    "# 70% training, 20% validation, 10% testing\n",
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebee62-e1af-4d79-bf96-44581e95df4d",
   "metadata": {},
   "source": [
    "# Sequential (Deep Learning) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e38077c-e6a6-459e-976a-f3ac7664266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7e8d62f-7165-461b-8b91-e7b2262f10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base sequential model\n",
    "model = Sequential()\n",
    "# Create the embedding layer \n",
    "model.add(Embedding(MAX_WORDS+1, 32))\n",
    "# Bidirectional (allows for two-way information passing, important for sentence cohesion in analysis) LSTM Layer, 'tanh' activation needed for LSTM layers\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "# Feature extractor fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Final layer, 6 for the number of toxicity labels, sigmoid converts outputs to ranges between 0-1 \n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e3dca69-388f-4db7-b8e8-114345144624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef9c8b55-5f0e-4b95-89a7-179c7a3481f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                16640     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6491686 (24.76 MB)\n",
      "Trainable params: 6491686 (24.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3805a6-4ee0-4a5c-a88b-74eb71c73756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3443/6981 [=============>................] - ETA: 24:18 - loss: 0.0718"
     ]
    }
   ],
   "source": [
    "model_training = model.fit(train, epochs=1, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b62e0b-7d41-4f84-9984-42dbb71bc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(model_training.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b19ab-7131-429d-a28c-50c5d8cf4195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "seminar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
